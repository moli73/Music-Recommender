{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human tastes in music are remarkably diverse, therefore music recommender is a best tool to help people find what they like. Moreover, more precisely music recommender recommend means more money music company can earn. So that it is a huge attraction for music company to improve their music recommender. However, the usual method collaborative filtering (CF) techniques suffer from a cold-start problem in many of the less popular items.\n",
    "Therefore, in order to increase the quality of recommender, we decide to implement a rich model for both the item and user biases, which accounts for the item taxonomy, user rating sessions. Besides, we expand basic personalization model to encompass more patterns observed in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large dataset from Yahoo! music KDD cup contest. It contain over 250 million ratings performed by over 1 million users. We cut "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Related Work\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several approaches to music recommendations:\n",
    "\n",
    "1) Collaborative Filtering (CF) methods utilize user feedback (explicit or implicit) to infer relations in users and items, and ultimately relate users to items they like. This approach do not use domain knowledge.\n",
    "Context Based Filtering methods characterize items based on textual attributes, cultural information, social tags and other kinds of web-based annotations. \n",
    "\n",
    "2) Given the nature of our dataset, we focus on a CF approach. However, algorithms based on basic collaborative filtering typically suffer from the cold-start problem when encountering items with little rating information. In our system [1], we use a taxonomy to share information between rated item, thus the representation of tracks with a little rating data naturally collapses to the representation of their respective album and artist which can lead to a better performance.\n",
    "\n",
    "We would first employ a Matrix Factorization (MF) model which can be found at [2]. Typically, a predicted rating by user u to item i given by **rui=μ+bi+bu+puTqi** where **puTqi** captures the affinity of user u to item i. Then, according to the base paper [1], we would enhance our bias model by letting item biases share components for items linked by the taxonomy and adding Items temporal dynamics to expand item bias component. Also, for personalization model, we introduce shared factor components to reflect the affinity of items linked by the taxonomy.\n",
    "\n",
    "[1] https://pdfs.semanticscholar.org/e886/83556de8361267f30fc94a67aa7c36a60fe6.pdf\n",
    "\n",
    "[2] https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data and Preprocess\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: https://webscope.sandbox.yahoo.com/catalog.php?datatype=c&did=48<br>\n",
    "List:\n",
    "\n",
    "1.trainIdx1.txt\n",
    "\n",
    "2.testIdx1.txt\n",
    "\n",
    "3.validationIdx1.txt\n",
    "\n",
    "4.trackData1.txt\n",
    "\n",
    "5.albumData1.txt\n",
    "\n",
    "6.artistData1.txt\n",
    "\n",
    "7.genreData1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset offers a wealth of information and services related to many aspects of music. We have compiled a dataset of user ratings of music items collected during a decade of using the Yahoo! Music website. The dataset was released within the first track of the KDD Cup 2011 contest. It comprises of 262,810,175 ratings of 624,961 items by 1,000,990 users. The ratings include both date and one-minute resolution timestamps, allowing refined temporal analysis. Each item and each user has at least 20 ratings in the whole dataset. The available ratings were split into train, validation and test sets such that the last 6 ratings of each user were placed in the test set and the preceding 4 ratings were used in the validation set. All earlier ratings (at least 10) comprise the train set. <br>\n",
    "In our project, we only use the part of the dataset to build our music recommender model in order to train our model quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transform the raw dataset into JSON file which is easy to read and use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def __items__preprocess__(input_filename, output_filename):\n",
    "    '''\n",
    "        This function is to split the raw trainning and test rating data JSON file\n",
    "        The inputfile should in same directory of the python script\n",
    "\t\tpython items_preprocess.py inputfilename outputfilename\n",
    "    '''\n",
    "    import re\n",
    "    import json\n",
    "    data = []\n",
    "    userRecord = {}#each user's record of all rating\n",
    "    with open(input_filename,'r') as f:\n",
    "        #read the first line\n",
    "        line = f.readline()\n",
    "        userRecord[\"ratings\"] = []\n",
    "        line_split = re.split(\"\\||\\n\", line)\n",
    "        if '' in line_split:\n",
    "            line_split.remove('')\n",
    "        userRecord['userID'] = line_split[0]\n",
    "        userRecord['numRating'] = line_split[1]\n",
    "        for line in f:\n",
    "            if '|' in line:\n",
    "                #output the former record\n",
    "                with open(output_filename, 'a') as wf:\n",
    "                    json.dump(userRecord.copy(), wf)\n",
    "                    wf.write(\"\\n\")\n",
    "                userRecord.clear()#clear the former userRating record\n",
    "                #construct the current record\n",
    "                userRecord[\"ratings\"] = []\n",
    "                line_split = re.split(\"\\||\\n\", line)\n",
    "                if '' in line_split:\n",
    "                    line_split.remove('')\n",
    "                userRecord['userID'] = line_split[0]\n",
    "                userRecord['numRating'] = line_split[1]\n",
    "            else:\n",
    "                line_split = re.split(\"\\t|\\n\", line)\n",
    "                if '' in line_split:\n",
    "                    line_split.remove('')\n",
    "                curRating = {}#current item rating of current user\n",
    "                curRating['itemID'] = line_split[0]\n",
    "                curRating['rating'] = line_split[1]\n",
    "                curRating['number'] = line_split[2]\n",
    "                curRating['time'] = line_split[3]\n",
    "                userRecord[\"ratings\"].append(curRating)\n",
    "    #store the last user\n",
    "    with open(output_filename, 'a') as wf:\n",
    "        json.dump(userRecord.copy(), wf)\n",
    "\n",
    "__items__preprocess__('trainIdx1.txt', 'trainOut.json')\n",
    "__items__preprocess__('testIdx1.txt', 'testOut.json')\n",
    "__items__preprocess__('validationIdx1.txt', 'validationOut.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def cutData(input_filename, output_filename, lines):\n",
    "    '''\n",
    "        cut the partial dataset\n",
    "    '''\n",
    "    with open(input_filename, 'r') as f:\n",
    "        for i in range(lines):\n",
    "            curUserReview = json.loads(f.readline())\n",
    "            with open(output_filename, 'a') as wf:\n",
    "                json.dump(curUserReview, wf)\n",
    "                wf.write('\\n')\n",
    "\n",
    "cutData('trainOut.json', 'trainOut1w.json', 10000)\n",
    "cutData('testOut.json', 'testOut1w.json', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delete users who rating = 0 \n",
    "import json\n",
    "def cutDataNoZero(input_filename, output_filename,lines):\n",
    "    '''\n",
    "        to eliminate the rating with 0 from trainOut dataset\n",
    "    '''\n",
    "    with open(input_filename, 'r') as f:\n",
    "        for i in range(lines):\n",
    "            curlist = []\n",
    "            curUserReview = json.loads(f.readline())\n",
    "            for j in range (len(curUserReview['ratings'])):\n",
    "                if int(curUserReview['ratings'][j]['rating']) != 0:\n",
    "                    curlist.append(curUserReview['ratings'][j])\n",
    "            if len(curlist)==0:\n",
    "                continue\n",
    "            curUserReview['ratings'] = curlist\n",
    "            with open (output_filename,'a') as wf:\n",
    "                json.dump(curUserReview,wf)\n",
    "                wf.write('\\n')\n",
    "                \n",
    "cutDataNoZero('trainOut1w.json', 'trainOutNoZero1w.json',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def __track__preprocess__(input_filename, output_filename):\n",
    "    '''\n",
    "        This function is to split the track data into JSON file\n",
    "        The inputfile should in same directory of the python script\n",
    "        python items_preprocess.py input_filename output_filename\n",
    "    '''\n",
    "    import re\n",
    "    import json\n",
    "    with open(input_filename, 'r') as f:\n",
    "        for line in f:\n",
    "            curTrack = {}#the information of current track\n",
    "            trackRecord = re.split('\\||\\n', line)\n",
    "            if '' in trackRecord:\n",
    "                trackRecord.remove('')\n",
    "            curTrack['trackID'] = trackRecord[0]\n",
    "            curTrack['albumID'] = trackRecord[1]\n",
    "            curTrack['artistID'] = trackRecord[2]\n",
    "            genreList = []\n",
    "            for i in range(3, len(trackRecord)):\n",
    "                genreList.append(trackRecord[i])\n",
    "            curTrack['genreList'] = genreList\n",
    "            with open(output_filename, 'a') as wf:\n",
    "                json.dump(curTrack, wf)\n",
    "                wf.write(\"\\n\")\n",
    "\n",
    "__track__preprocess__(\"trackData1.txt\", \"trackOut.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def __album__preprocess__(input_filename, output_filename):\n",
    "    '''\n",
    "        This function is to split the album data into JSON file\n",
    "        The inputfile should in same directory of the python script\n",
    "        python items_preprocess.py input_filename output_filename\n",
    "    '''\n",
    "    import re\n",
    "    import json\n",
    "    data = []\n",
    "    with open(input_filename, 'r') as f:\n",
    "        for line in f:\n",
    "            curAlbum = {}#the information of current album\n",
    "            albumRecord = re.split('\\||\\n', line)\n",
    "            if '' in albumRecord:\n",
    "                albumRecord.remove('')\n",
    "            curAlbum['albumID'] = albumRecord[0]\n",
    "            curAlbum['artistID'] = albumRecord[1]\n",
    "            genreList = []\n",
    "            for i in range(2, len(albumRecord)):\n",
    "                genreList.append(albumRecord[i])\n",
    "            curAlbum['genreList'] = genreList\n",
    "            # data.append(curAlbum.copy())\n",
    "            with open(output_filename, 'a') as wf:\n",
    "                json.dump(curAlbum, wf)\n",
    "                wf.write('\\n')\n",
    "                \n",
    "__album__preprocess__(\"albumData1.txt\", \"albumOut.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractID(input_filename, output_filename,itemID):\n",
    "    '''\n",
    "        extract ID of album and track\n",
    "    '''\n",
    "    itemList = []\n",
    "    with open(input_filename, 'r') as f:\n",
    "        for line in f:\n",
    "            itemList.append(json.loads(line))\n",
    "    \n",
    "    file_object = open(output_filename, 'w')\n",
    "    for i in range(len(itemList)):\n",
    "        ID = itemList[i][itemID]\n",
    "        file_object.write(ID)\n",
    "        file_object.write('\\n')\n",
    "    file_object.close()\n",
    "\n",
    "extractID('albumOut.json','album_out_idOnly.json','albumID') \n",
    "extractID('trackOut.json','track_out_idOnly.json','trackID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Approach / Methods\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Basic Bias Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
<<<<<<< HEAD
   "source": [
    "a) In the context of rating systems, biases model the portion of the observed signal that is derived either solely by the rating user or solely by rated item, but not by their interaction. A general framework for capturing the bias of the rating by user u to item i is described as:\n",
    "\n",
    "\\begin{equation} b_{ui} = µ + B_{i} + B_{u} \\end{equation}      \n",
    "\n",
    "where $µ$ is the overall mean rating value (a constant), and $B_{i}$ and $B_{u}$ stand for item and user biases, respectively.\n",
    "\n",
    "b) Following this general framework, we set the item bias $B_{i}$ as a distinct parameter associated with each item denoted\n",
    "by $b_{i}$, and similarly the user bias $B_{u}$ as a user-specific parameter\n",
    "$b_{u}$. This gives rise to the model:\n",
    "\n",
    "\\begin{equation} b_{ui} = µ + b_{i} + b_{u} \\end{equation}"
   ]
=======
   "source": []
>>>>>>> 8b0747d3d30698f4aef1b4a378384d18273d3383
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from math import sqrt\n",
    "\n",
    "def readData(filename, list):\n",
    "    '''\n",
    "        read the JSON file to list\n",
    "    '''\n",
    "\twith open(filename, 'r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tlist.append(json.loads(line))\n",
    "\n",
    "#load the trainning data\n",
    "trainDatas = []\n",
    "readData('trainOut1w.json', trainDatas)\n",
    "print(\"the number of users in trainning data is:\" + str(len(trainDatas)) + \"\\n\")\n",
    "\n",
    "\n",
    "#construct the dict by itemID\n",
    "trainReviews = {}#improve the speed of finding\n",
    "for review in trainDatas:\n",
    "    for rating in review[\"ratings\"]:\n",
    "        itemID = rating[\"itemID\"]\n",
    "        if itemID in trainReviews:\n",
    "            trainReviews[itemID].append(rating)\n",
    "        else:\n",
    "            trainReviews[itemID] = [rating]\n",
    "print('the number of distinct items is: ' + str(len(trainReviews)))\n",
    "\n",
    "#load the test data\n",
    "testDatas = []\n",
    "# readData('data_preprocess/testOut2w.json', testDatas)\n",
    "readData('testOut1w.json', testDatas)\n",
    "print(\"the number of users in test data is:\" + str(len(testDatas)) + \"\\n\")\n",
    "\n",
    "#the average of all rating\n",
    "aveRate = 0\n",
    "count = 0\n",
    "for review in trainDatas:\n",
    "    for rating in review[\"ratings\"]:\n",
    "        aveRate += int(rating[\"rating\"])\n",
    "        count += 1\n",
    "aveRate /= float(count)\n",
    "print('the overall average rating is: ' + str(aveRate))\n",
    "\n",
    "def itemBias(itemID, aveRating):\n",
    "    '''\n",
    "        use the trainReviews(dict) which is sorted by itemId\n",
    "    '''\n",
    "    numRating = 0\n",
    "    sumRating = 0\n",
    "    if itemID in trainReviews:\n",
    "        for rating in trainReviews[itemID]:\n",
    "            numRating += 1\n",
    "            sumRating += float(rating['rating'])\n",
    "    else:#if there is no such itemID's rating the itemBias is zero\n",
    "        return 0\n",
    "    return sumRating / float(numRating) - aveRating\n",
    "\n",
    "def userBias(userID, aveRating):\n",
    "    '''\n",
    "        use the trainOut format to find the userBias\n",
    "    '''\n",
    "    numRating = 0\n",
    "    sumRating = 0\n",
    "    for review in trainDatas:\n",
    "        if review['userID'] == userID:\n",
    "            for rating in review[\"ratings\"]:\n",
    "                numRating += 1\n",
    "                sumRating += float(rating['rating'])\n",
    "            break#if get the user info then stop the loop\n",
    "    if numRating == 0:\n",
    "        return 0\n",
    "    return sumRating / float(numRating) - aveRating\n",
    "\n",
    "#get the user bias matrix from train data\n",
    "userBiases = {}\n",
    "for review in trainDatas:\n",
    "\tuserID = review['userID']\n",
    "\tuserBiases[userID] = userBias(userID, aveRate)\n",
    "\n",
    "#get the item bias matrix from train data\n",
    "itemBiases = {}\n",
    "for itemID in trainReviews:\n",
    "    itemBiases[itemID] = itemBias(itemID, aveRate)\n",
    "    \n",
    "#check basic model RMSE\n",
    "errors = []\n",
    "count = 0\n",
    "squareSum = 0\n",
    "for review in testDatas:\n",
    "    userID = review['userID']\n",
    "    for rating in review['ratings']:\n",
    "        itemID = rating['itemID']\n",
    "        realRating = float(rating['rating'])\n",
    "        count += 1\n",
    "        if itemID in itemBiases:\n",
    "            squareSum += (aveRate + userBiases[userID] + itemBiases[itemID] - realRating) ** 2\n",
    "            errors.append(aveRate + userBiases[userID] + itemBiases[itemID] - realRating)\n",
    "        #if the current item does not exist in train data, the bias is zero\n",
    "        else:\n",
    "            squareSum += (aveRate + userBiases[userID] + 0 - realRating) ** 2\n",
    "            errors.append(aveRate + userBiases[userID] + 0 - realRating)\n",
    "\n",
    "RMSE = sqrt(squareSum / float(count))\n",
    "print('the basic model RMSE is: ' + str(RMSE))\n",
    "print('the number of views in test data is: ' + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Bias Model with Items Taxonomy **"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start improving our bias model by letting item biases share components for items linked by the taxonomy. For example, tracks in a good album may all be rated somewhat higher than the average, or a popular artist may have all her songs rated a bit higher than the average. We therefore add shared bias parameters to different items with a common ancestor in the taxonomy hierarchy. We expand the item bias model **for tracks** as follows:\n",
    "\n",
    "\\begin{equation} B_{i} = b_{i} + b_{album(i)} + b_{artist(i)} + \\frac{1}{|genres(i)|} \\sum_{g\\in genres(i)}^{}b_{g}\\end{equation}\n",
    "\n",
    "Similarly, **for albums** we expand the bias model as follows:\n",
    "\n",
    "\\begin{equation} B_{i} = b_{i} + b_{artist(i)} + \\frac{1}{|genres(i)|} \\sum_{g\\in genres(i)}^{}b_{g}\\end{equation}\n",
    "\n",
    "while artists and genres are less susceptible to the sparsity problem, they also benefit from this model as any rating to track and album also influences the biases of their corresponding artist and genre. **For artists** we expand the bias model as follows:\n",
    "\n",
    "\\begin{equation} B_{i} = b_{i} + \\frac{1}{|genres(i)|} \\sum_{g\\in genres(i)}^{}b_{g}\\end{equation}\n",
    "\n"
   ]
  },
  {
=======
>>>>>>> 8b0747d3d30698f4aef1b4a378384d18273d3383
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the 4 type's all ID\n",
    "def readIDData(filename):\n",
    "    '''\n",
    "        read JSON file and return list\n",
    "    '''\n",
    "\tlist = []\n",
    "\twith open(filename, 'r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tlist.append(line[:-1])#eliminate the newline character\n",
    "\treturn list\n",
    "#use add taxonomy bias\n",
    "trackList = readIDData('track_out_idOnly.txt')\n",
    "artistList = readIDData('artistData1.txt')\n",
    "albumList = readIDData('album_out_idOnly.txt')\n",
    "genreList = readIDData('genreData1.txt')\n",
    "\n",
    "print('the length of track list is:' + str(len(trackList)))\n",
    "print('the length of artistList is:' + str(len(artistList)))\n",
    "print('the length of albumList is:' + str(len(albumList)))\n",
    "print('the length of genreList is:' + str(len(genreList)))\n",
    "\n",
    "\n",
    "##\n",
    "#  extract the items biases with different types from the partial trainData\n",
    "##\n",
    "#extract the track bias\n",
    "trackBiases = {}\n",
    "for itemID in trackList:\n",
    "\tif itemID in trainReviews:\n",
    "\t\tsumRating = 0\n",
    "\t\tnumRating = 0\n",
    "\t\tfor rating in trainReviews[itemID]:\n",
    "\t\t\tsumRating += float(rating['rating'])\n",
    "\t\t\tnumRating += 1\n",
    "\t\ttrackBiases[itemID] = float(sumRating) / float(numRating) - aveRate\n",
    "\telse:\n",
    "\t\ttrackBiases[itemID] = 0\n",
    "print('the size of trackBiases is: ' + str(len(trackBiases)))\n",
    "\n",
    "#extract the album bias\n",
    "albumBiases = {}\n",
    "for itemID in albumList:\n",
    "\tif itemID in trainReviews:\n",
    "\t\tsumRating = 0\n",
    "\t\tnumRating = 0\n",
    "\t\tfor rating in trainReviews[itemID]:\n",
    "\t\t\tsumRating += float(rating['rating'])\n",
    "\t\t\tnumRating += 1\n",
    "\t\talbumBiases[itemID] = float(sumRating) / float(numRating) - aveRate\n",
    "\telse:\n",
    "\t\talbumBiases[itemID] = 0\n",
    "print('the size of albumBiases is: ' + str(len(albumBiases)))\n",
    "\n",
    "#extract the artist bias\n",
    "artistBiases = {}\n",
    "for itemID in artistList:\n",
    "\tif itemID in trainReviews:\n",
    "\t\tsumRating = 0\n",
    "\t\tnumRating = 0\n",
    "\t\tfor rating in trainReviews[itemID]:\n",
    "\t\t\tsumRating += float(rating['rating'])\n",
    "\t\t\tnumRating += 1\n",
    "\t\tartistBiases[itemID] = float(sumRating) / float(numRating) - aveRate\n",
    "\telse:\n",
    "\t\tartistBiases[itemID] = 0\n",
    "print('the size of artistBiases is: ' + str(len(artistBiases)))\n",
    "\n",
    "#extract the genre bias\n",
    "genreBiases = {}\n",
    "for itemID in genreList:\n",
    "\tif itemID in trainReviews:\n",
    "\t\tsumRating = 0\n",
    "\t\tnumRating = 0\n",
    "\t\tfor rating in trainReviews[itemID]:\n",
    "\t\t\tsumRating += float(rating['rating'])\n",
    "\t\t\tnumRating += 1\n",
    "\t\tgenreBiases[itemID] = float(sumRating) / float(numRating) - aveRate\n",
    "\telse:\n",
    "\t\tgenreBiases[itemID] = 0\n",
    "print('the size of genreBiases is: ' + str(len(genreBiases)))\n",
    "\n",
    "#read the tracks\n",
    "trackDatas = []\n",
    "readData('trackOut.json', trackDatas)\n",
    "print('the size of track is: ' + str(len(trackDatas)))\n",
    "\n",
    "#construct the dict by trackID\n",
    "trackDict = {}\n",
    "for track in trackDatas:\n",
    "    trackDict[track['trackID']] = track\n",
    "print('the number of tracks is: ' + str(len(trackDict)))\n",
    "\n",
    "#expand the track bias with taxonomy\n",
    "def getTaxTrackBias(itemID):\n",
    "    if itemID in trackBiases:#should check this, since not all track in this partial train data\n",
    "        bi = trackBiases[itemID]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    genreRateSum = 0\n",
    "    genreNum = 0\n",
    "    biGenre = 0\n",
    "    biAlbum = 0\n",
    "    biArtist = 0\n",
    "    \n",
    "    track = trackDict[itemID]\n",
    "    if track[\"albumID\"] in albumBiases:\n",
    "        #assume that the track only belong to exactly one album\n",
    "        biAlbum = albumBiases[track[\"albumID\"]]\n",
    "            \n",
    "    if track['artistID'] in artistBiases:\n",
    "        #assume that the track only belong to exactly one artist\n",
    "        biArtist = artistBiases[track[\"artistID\"]]\n",
    "            \n",
    "    for genreID in track['genreList']:\n",
    "        if genreID in genreBiases:\n",
    "            genreRateSum += genreBiases[genreID]\n",
    "            genreNum += 1\n",
    "        if genreNum != 0:\n",
    "            biGenre = float(genreRateSum) / float(genreNum)\n",
    "        \n",
    "    taxTrackBias = bi + biAlbum + biArtist + biGenre\n",
    "\n",
    "    return taxTrackBias\n",
    "\n",
    "#pre-build the trackTaxBiases\n",
    "trackTaxBiases = {}\n",
    "for itemID in trainReviews:\n",
    "    if itemID in trackBiases:\n",
    "        trackTaxBiases[itemID] = getTaxTrackBias(itemID)\n",
    "print('the size of track tax biases is: ' + str(len(trackTaxBiases)))\n",
    "\n",
    "#read the albums \n",
    "albumDatas = []\n",
    "readData('data_preprocess/albumOut.json', albumDatas)\n",
    "print('the size of album is: ' + str(len(albumDatas)))\n",
    "\n",
    "#construct the dict by albumID\n",
    "albumDict = {}\n",
    "for album in albumDatas:\n",
    "    albumDict[album['albumID']] = album\n",
    "print('the number of albums is: ' + str(len(albumDict)))\n",
    "\n",
    "#expand the album bias\n",
    "def getTaxAlbumBias(itemID):\n",
    "    if itemID in albumBiases:#should check this, since not all album in this partial data\n",
    "\t\tbi = albumBiases[itemID]\n",
    "    else:\n",
    "\t\treturn 0\n",
    "    \n",
    "    genreRateSum = 0\n",
    "    genreNum = 0\n",
    "    biGenre = 0\n",
    "    biArtist = 0\n",
    "    \n",
    "    album = albumDict[itemID]\n",
    "    if album['artistID'] in artistBiases:\n",
    "        #assume that the album only belong to exactly one artist\n",
    "        biArtist = artistBiases[album[\"artistID\"]]\n",
    "            \n",
    "    for genreID in album['genreList']:\n",
    "        if genreID in genreBiases:\n",
    "            genreRateSum += genreBiases[genreID]\n",
    "            genreNum += 1\n",
    "        if genreNum != 0:\n",
    "            biGenre = float(genreRateSum) / float(genreNum)\n",
    "    \n",
    "    taxAlbumBias = bi + biArtist + biGenre\n",
    "    return taxAlbumBias\n",
    "\n",
    "#pre-build the albumTaxBiases\n",
    "albumTaxBiases = {}\n",
    "for itemID in trainReviews:\n",
    "    if itemID in albumBiases:\n",
    "        albumTaxBiases[itemID] = getTaxAlbumBias(itemID)\n",
    "print('the size of album tax biases is: ' + str(len(albumTaxBiases)))\n",
    "\n",
    "#check the taxonomy bias model RMSE\n",
    "errors = []\n",
    "count = 0\n",
    "squareSum = 0\n",
    "for review in testDatas:\n",
    "    userID = review['userID']\n",
    "    for rating in review['ratings']:\n",
    "        itemID = rating['itemID']\n",
    "        realRating = float(rating['rating'])\n",
    "        count += 1\n",
    "        if itemID in itemBiases:\n",
    "            if itemID in trackBiases:\n",
    "                curItemBias = trackTaxBiases[itemID]              \n",
    "            elif itemID in albumBiases:\n",
    "                curItemBias = albumTaxBiases[itemID]               \n",
    "            else:\n",
    "                curItemBias = itemBiases[itemID]\n",
    "        #if the current item does not exist in train data, the bias is zero\n",
    "        else:\n",
    "            curItemBias = 0\n",
    "        curUserBias = userBiases[userID]\n",
    "            \n",
    "        squareSum += (aveRate + curItemBias + curUserBias - realRating) ** 2\n",
    "        errors.append(aveRate + curItemBias + curUserBias - realRating)\n",
    "\n",
    "RMSE = sqrt(squareSum / float(count))\n",
    "print('the item taxonomy model RMSE is: ' + str(RMSE))\n",
    "print('the number of views in test data is: ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 Bias Model with Users Taxonomy **"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of adding taxonomy bias of items is also useful for expanding the user bias model. Since a user may tend to rate artists or genres higher than songs. Therefore, given an item $i$, the user bias is: \n",
    "\n",
    "\\begin{equation} B_{u} = b_{u} + b_{u,types(i)}\\end{equation}\n",
    "\n",
    "where $b_{u}$ is the user specific bias component and $b_{u,types(i)}$ is a shared component of all the ratings by user $u$ to items of type $type(i)$."
   ]
  },
  {
=======
>>>>>>> 8b0747d3d30698f4aef1b4a378384d18273d3383
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def userTaxBias(userID):\n",
    "    bu = userBiases[userID]\n",
    "    userTaxBiases = {'track':0,'album':0,'artist':0,'genre':0}\n",
    "    numTrackRate = 0\n",
    "    numAlbumRate = 0\n",
    "    numArtistRate = 0\n",
    "    numGenreRate = 0\n",
    "    \n",
    "    sumTrackRate = 0\n",
    "    sumAlbumRate = 0\n",
    "    sumArtistRate = 0\n",
    "    sumGenreRate = 0\n",
    "\n",
    "    review = trainDatas[int(userID) - 30000]#since the ID of users is continuous\n",
    "    for rating in review['ratings']:\n",
    "        itemID = rating['itemID']\n",
    "        score = float(rating['rating'])\n",
    "        if itemID in trackBiases:\n",
    "            sumTrackRate += score\n",
    "            numTrackRate += 1\n",
    "        elif itemID in albumBiases:\n",
    "            sumAlbumRate += score\n",
    "            numAlbumRate += 1\n",
    "        elif itemID in artistBiases:\n",
    "            sumArtistRate += score\n",
    "            numArtistRate += 1\n",
    "        elif itemID in genreBiases:\n",
    "            sumGenreRate += score\n",
    "            numGenreRate += 1\n",
    "    if numTrackRate != 0:\n",
    "        userTaxBiases['track'] = sumTrackRate / float(numTrackRate) - aveRate\n",
    "    if numAlbumRate != 0:   \n",
    "        userTaxBiases['album'] = sumAlbumRate / float(numAlbumRate) - aveRate\n",
    "    if numArtistRate != 0:\n",
    "        userTaxBiases['artist'] = sumArtistRate / float(numArtistRate) - aveRate\n",
    "    if numGenreRate != 0:\n",
    "        userTaxBiases['genre'] = sumGenreRate / float(numGenreRate) - aveRate\n",
    "    \n",
    "    return userTaxBiases\n",
    "\n",
    "#pre-build the tax user biases\n",
    "userTaxBiases = {}\n",
    "for review in trainDatas:\n",
    "    userID = review['userID']\n",
    "    userTaxBiases[userID] = userTaxBias(userID)\n",
    "print('the number of users in train data is: ' + str(len(userTaxBiases)))\n",
    "\n",
    "#check the RMSE with full taxonomy bias model\n",
    "errors = []\n",
    "count = 0\n",
    "squareSum = 0\n",
    "for review in testDatas:\n",
    "    userID = review['userID']\n",
    "    for rating in review['ratings']:\n",
    "        itemID = rating['itemID']\n",
    "        realRating = float(rating['rating'])\n",
    "        count += 1\n",
    "        if itemID in itemBiases:\n",
    "            if itemID in trackBiases:\n",
    "                curItemBias = trackTaxBiases[itemID]\n",
    "                curUserBias = userTaxBiases[userID]['track']\n",
    "            elif itemID in albumBiases:\n",
    "                curItemBias = albumTaxBiases[itemID]\n",
    "                curUserBias = userTaxBiases[userID]['album']\n",
    "            else:\n",
    "                if itemID in artistBiases:\n",
    "                    curUserBias = userTaxBiases[userID]['artist']\n",
    "                elif itemID in genreBiases:\n",
    "                    curUserBias = userTaxBiases[userID]['genre']\n",
    "                curItemBias = itemBiases[itemID]\n",
    "        #if the current item does not exist in train data, the bias is zero\n",
    "        else:\n",
    "            curItemBias = 0\n",
    "        squareSum += (aveRate + curItemBias + curUserBias - realRating) ** 2 \n",
    "        errors.append(aveRate + curItemBias + curUserBias - realRating)\n",
    "#         squareSum += (aveRate + userBiases[userID] + curItemBias + curUserBias - realRating) ** 2\n",
    "\n",
    "            \n",
    "RMSE = sqrt(squareSum / float(count))\n",
    "print('the full taxonomy model RMSE is: ' + str(RMSE))\n",
    "print('the number of views in test data is: ' + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4 Bias Model with Users Session**"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distinctive property of the Yahoo! Music dataset is its temporal information. Each rating is marked by a date and a timestamp. In this part we will use this information and start by modeling user sessions. Unlike movies, in music it is common for users to listen to many songs and rate them one after the other. A rating session is therefore a set of consecutive ratings without an extended time gap between them. There are many psychological phenomena that affect ratings grouped in a single session. These effects are captured by user session biases.\n",
    "\n",
    "To take such effects into account, we added a session bias term to our user bias model. We thus marked users’ consecutive ratings with session numbers separated by a time gap of at least 5 hours in which the user was idle (no rating activity). We denote by $session(u,i)$ the rating session of the rating $r_{ui}$, and expand ouruser bias model to include session biases:\n",
    "\n",
    "\\begin{equation} B_{u} = B_{u} + b_{u,session(i,u)}\\end{equation}\n",
    "\n",
    "The session bias parameter $b_{u,session(i,u)}$ models the bias component common to all ratings of $u$ in the same session he rated $i$."
   ]
  },
  {
=======
>>>>>>> 8b0747d3d30698f4aef1b4a378384d18273d3383
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUserSessionBias(ratings):\n",
    "    userSessionBias = {}\n",
    "    count = {}\n",
    "    for rating in ratings:\n",
    "        number = rating['number']\n",
    "        if number in userSessionBias:\n",
    "            userSessionBias[number] += float(rating['rating'])\n",
    "            count[number] += 1\n",
    "        else:\n",
    "            userSessionBias[number] = float(rating['rating'])\n",
    "            count[number] = 1\n",
    "    for number in userSessionBias.keys():\n",
    "        userSessionBias[number] = userSessionBias[number] / float(count[number]) - aveRate\n",
    "    return userSessionBias\n",
    "\n",
    "#get the user's session biases \n",
    "userSessionBiases = {}\n",
    "for review in trainDatas:\n",
    "    userID = review['userID']\n",
    "    userSessionBiases[userID] = getUserSessionBias(review['ratings'])\n",
    "    \n",
    "#check the RMSE with addtion of user session bias\n",
    "# predRatings = []\n",
    "# realRatings = []\n",
    "errors = []\n",
    "count = 0\n",
    "squareSum = 0\n",
    "for review in testDatas:\n",
    "    userID = review['userID']\n",
    "    for rating in review['ratings']:\n",
    "        itemID = rating['itemID']\n",
    "        realRating = float(rating['rating'])\n",
    "        count += 1\n",
    "        if itemID in itemBiases:\n",
    "            if itemID in trackBiases:\n",
    "                curItemBias = trackTaxBiases[itemID]\n",
    "                curUserBias = userTaxBiases[userID]['track']\n",
    "            elif itemID in albumBiases:\n",
    "                curItemBias = albumTaxBiases[itemID]\n",
    "                curUserBias = userTaxBiases[userID]['album']\n",
    "            else:\n",
    "                if itemID in artistBiases:\n",
    "                    curUserBias = userTaxBiases[userID]['artist']\n",
    "                elif itemID in genreBiases:\n",
    "                    curUserBias = userTaxBiases[userID]['genre']\n",
    "                curItemBias = itemBiases[itemID]\n",
    "        #if the current item does not exist in train data, the bias is zero\n",
    "        else:\n",
    "            curItemBias = 0\n",
    "        #check if user has session bias\n",
    "        if rating['number'] in userSessionBiases[userID]:\n",
    "            curUserBias += userSessionBiases[userID][rating['number']]\n",
    "        \n",
    "        \n",
    "        squareSum += (aveRate + curItemBias + curUserBias - realRating) ** 2 \n",
    "#         predRatings.append(aveRate + curItemBias + curUserBias)\n",
    "#         realRatings.append(realRating)\n",
    "        errors.append(aveRate + curItemBias + curUserBias - realRating)\n",
    "#         squareSum += (aveRate + userBiases[userID] + curItemBias + curUserBias - realRating) ** 2\n",
    "          \n",
    "RMSE = sqrt(squareSum / float(count))\n",
    "print('the full taxonomy model with user session bias RMSE is: ' + str(RMSE))\n",
    "print('the number of views in test data is: ' + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.5 Model with Partial trainning **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from math import sqrt\n",
    "\n",
    "def readData(filename, list):\n",
    "\twith open(filename, 'r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tlist.append(json.loads(line))\n",
    "\n",
    "#load the trainning data\n",
    "trainDatas = []\n",
    "readData('trainOutNoZero.json', trainDatas)\n",
    "print(\"the number of users in trainning data is:\" + str(len(trainDatas)) + \"\\n\")\n",
    "\n",
    "#construct the dict by itemID\n",
    "trainReviews = {}#improve the speed of finding\n",
    "for review in trainDatas:\n",
    "    for rating in review[\"ratings\"]:\n",
    "        itemID = rating[\"itemID\"]\n",
    "        if itemID in trainReviews:\n",
    "            trainReviews[itemID].append(rating)\n",
    "        else:\n",
    "            trainReviews[itemID] = [rating]\n",
    "print('the number of distinct items is: ' + str(len(trainReviews)))\n",
    "\n",
    "#the average of all rating\n",
    "aveRate = 0\n",
    "count = 0\n",
    "for review in trainDatas:\n",
    "    for rating in review[\"ratings\"]:\n",
    "        aveRate += int(rating[\"rating\"])\n",
    "        count += 1\n",
    "aveRate /= float(count)\n",
    "print('the overall average rating is: ' + str(aveRate))\n",
    "\n",
    "def itemBias(itemID, aveRating):\n",
    "\n",
    "    #    use the trainReviews(dict) which is sorted by itemId\n",
    "\n",
    "    numRating = 0\n",
    "    sumRating = 0\n",
    "    if itemID in trainReviews:\n",
    "        for rating in trainReviews[itemID]:\n",
    "            numRating += 1\n",
    "            sumRating += float(rating['rating'])\n",
    "    else:#if there is no such itemID's rating the itemBias is zero\n",
    "        return 0\n",
    "    return sumRating / float(numRating) - aveRating\n",
    "\n",
    "def userBias(userID, aveRating):\n",
    "\n",
    "    #    use the trainOut format to find the userBias\n",
    "\n",
    "    numRating = 0\n",
    "    sumRating = 0\n",
    "    for review in trainDatas:\n",
    "        if review['userID'] == userID:\n",
    "            for rating in review[\"ratings\"]:\n",
    "                numRating += 1\n",
    "                sumRating += float(rating['rating'])\n",
    "            break#if get the user info then stop the loop\n",
    "    if numRating == 0:\n",
    "        return 0\n",
    "    return sumRating / float(numRating) - aveRating\n",
    "\n",
    "#get the user bias matrix from train data\n",
    "userBiases = {}\n",
    "for review in trainDatas:\n",
    "\tuserID = review['userID']\n",
    "\tuserBiases[userID] = userBias(userID, aveRate)\n",
    "\n",
    "#get the item bias matrix from train data\n",
    "itemBiases = {}\n",
    "for itemID in trainReviews:\n",
    "    itemBiases[itemID] = itemBias(itemID, aveRate)\n",
    "    \n",
    "##\n",
    "#  extract the items biases with different types from the partial trainData\n",
    "##\n",
    "#extract the track bias\n",
    "trackBiases = {}\n",
    "for itemID in trackList:\n",
    "\tif itemID in trainReviews:\n",
    "\t\tsumRating = 0\n",
    "\t\tnumRating = 0\n",
    "\t\tfor rating in trainReviews[itemID]:\n",
    "\t\t\tsumRating += float(rating['rating'])\n",
    "\t\t\tnumRating += 1\n",
    "\t\ttrackBiases[itemID] = float(sumRating) / float(numRating) - aveRate\n",
    "\telse:\n",
    "\t\ttrackBiases[itemID] = 0\n",
    "print('the size of trackBiases is: ' + str(len(trackBiases)))\n",
    "\n",
    "#extract the album bias\n",
    "albumBiases = {}\n",
    "for itemID in albumList:\n",
    "\tif itemID in trainReviews:\n",
    "\t\tsumRating = 0\n",
    "\t\tnumRating = 0\n",
    "\t\tfor rating in trainReviews[itemID]:\n",
    "\t\t\tsumRating += float(rating['rating'])\n",
    "\t\t\tnumRating += 1\n",
    "\t\talbumBiases[itemID] = float(sumRating) / float(numRating) - aveRate\n",
    "\telse:\n",
    "\t\talbumBiases[itemID] = 0\n",
    "print('the size of albumBiases is: ' + str(len(albumBiases)))\n",
    "\n",
    "#extract the artist bias\n",
    "artistBiases = {}\n",
    "for itemID in artistList:\n",
    "\tif itemID in trainReviews:\n",
    "\t\tsumRating = 0\n",
    "\t\tnumRating = 0\n",
    "\t\tfor rating in trainReviews[itemID]:\n",
    "\t\t\tsumRating += float(rating['rating'])\n",
    "\t\t\tnumRating += 1\n",
    "\t\tartistBiases[itemID] = float(sumRating) / float(numRating) - aveRate\n",
    "\telse:\n",
    "\t\tartistBiases[itemID] = 0\n",
    "print('the size of artistBiases is: ' + str(len(artistBiases)))\n",
    "\n",
    "#extract the genre bias\n",
    "genreBiases = {}\n",
    "for itemID in genreList:\n",
    "\tif itemID in trainReviews:\n",
    "\t\tsumRating = 0\n",
    "\t\tnumRating = 0\n",
    "\t\tfor rating in trainReviews[itemID]:\n",
    "\t\t\tsumRating += float(rating['rating'])\n",
    "\t\t\tnumRating += 1\n",
    "\t\tgenreBiases[itemID] = float(sumRating) / float(numRating) - aveRate\n",
    "\telse:\n",
    "\t\tgenreBiases[itemID] = 0\n",
    "print('the size of genreBiases is: ' + str(len(genreBiases)))\n",
    "\n",
    "#read the tracks\n",
    "trackDatas = []\n",
    "readData('data_preprocess/trackOut.json', trackDatas)\n",
    "print('the size of track is: ' + str(len(trackDatas)))\n",
    "print(trackDatas[0])\n",
    "\n",
    "#construct the dict by trackID\n",
    "trackDict = {}\n",
    "for track in trackDatas:\n",
    "    trackDict[track['trackID']] = track\n",
    "print('the number of tracks is: ' + str(len(trackDict)))\n",
    "print(trackDict['0'])\n",
    "\n",
    "#expand the track bias\n",
    "def getTaxTrackBias(itemID):\n",
    "    if itemID in trackBiases:#should check this, since not all track in this partial train data\n",
    "        bi = trackBiases[itemID]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    genreRateSum = 0\n",
    "    genreNum = 0\n",
    "    biGenre = 0\n",
    "    biAlbum = 0\n",
    "    biArtist = 0\n",
    "    \n",
    "    track = trackDict[itemID]\n",
    "    if track[\"albumID\"] in albumBiases:\n",
    "        #assume that the track only belong to exactly one album\n",
    "        biAlbum = albumBiases[track[\"albumID\"]]\n",
    "            \n",
    "    if track['artistID'] in artistBiases:\n",
    "        #assume that the track only belong to exactly one artist\n",
    "        biArtist = artistBiases[track[\"artistID\"]]\n",
    "            \n",
    "    for genreID in track['genreList']:\n",
    "        if genreID in genreBiases:\n",
    "            genreRateSum += genreBiases[genreID]\n",
    "            genreNum += 1\n",
    "        if genreNum != 0:\n",
    "            biGenre = float(genreRateSum) / float(genreNum)\n",
    "        \n",
    "    taxTrackBias = bi + biAlbum + biArtist + biGenre\n",
    "\n",
    "    return taxTrackBias\n",
    "\n",
    "#pre-build the trackTaxBiases\n",
    "trackTaxBiases = {}\n",
    "for itemID in trainReviews:\n",
    "    if itemID in trackBiases:\n",
    "        trackTaxBiases[itemID] = getTaxTrackBias(itemID)\n",
    "print('the size of track tax biases is: ' + str(len(trackTaxBiases)))\n",
    "# print(trackTaxBiases['0'])\n",
    "\n",
    "#read the albums \n",
    "albumDatas = []\n",
    "readData('data_preprocess/albumOut.json', albumDatas)\n",
    "print('the size of album is: ' + str(len(albumDatas)))\n",
    "\n",
    "#construct the dict by albumID\n",
    "albumDict = {}\n",
    "for album in albumDatas:\n",
    "    albumDict[album['albumID']] = album\n",
    "print('the number of albums is: ' + str(len(albumDict)))\n",
    "\n",
    "#expand the album bias\n",
    "def getTaxAlbumBias(itemID):\n",
    "    if itemID in albumBiases:#should check this, since not all album in this partial data\n",
    "\t\tbi = albumBiases[itemID]\n",
    "    else:\n",
    "\t\treturn 0\n",
    "    \n",
    "    genreRateSum = 0\n",
    "    genreNum = 0\n",
    "    biGenre = 0\n",
    "    biArtist = 0\n",
    "    \n",
    "    album = albumDict[itemID]\n",
    "    if album['artistID'] in artistBiases:\n",
    "        #assume that the album only belong to exactly one artist\n",
    "        biArtist = artistBiases[album[\"artistID\"]]\n",
    "            \n",
    "    for genreID in album['genreList']:\n",
    "        if genreID in genreBiases:\n",
    "            genreRateSum += genreBiases[genreID]\n",
    "            genreNum += 1\n",
    "        if genreNum != 0:\n",
    "            biGenre = float(genreRateSum) / float(genreNum)\n",
    "    \n",
    "    taxAlbumBias = bi + biArtist + biGenre\n",
    "    return taxAlbumBias\n",
    "\n",
    "#pre-build the albumTaxBiases\n",
    "albumTaxBiases = {}\n",
    "for itemID in trainReviews:\n",
    "    if itemID in albumBiases:\n",
    "        albumTaxBiases[itemID] = getTaxAlbumBias(itemID)\n",
    "print('the size of album tax biases is: ' + str(len(albumTaxBiases)))\n",
    "\n",
    "def userTaxBias(userID):\n",
    "    bu = userBiases[userID]\n",
    "    userTaxBiases = {'track':0,'album':0,'artist':0,'genre':0}\n",
    "    numTrackRate = 0\n",
    "    numAlbumRate = 0\n",
    "    numArtistRate = 0\n",
    "    numGenreRate = 0\n",
    "    \n",
    "    sumTrackRate = 0\n",
    "    sumAlbumRate = 0\n",
    "    sumArtistRate = 0\n",
    "    sumGenreRate = 0\n",
    "\n",
    "#     review = trainDatas[int(userID) - 30000]#since the ID of users is continuous\n",
    "    for curReview in trainDatas:\n",
    "        if curReview['userID'] == userID:\n",
    "            review = curReview#since the ID of users is continuous\n",
    "            break\n",
    "    \n",
    "    for rating in review['ratings']:\n",
    "        itemID = rating['itemID']\n",
    "        score = float(rating['rating'])\n",
    "        if itemID in trackBiases:\n",
    "            sumTrackRate += score\n",
    "            numTrackRate += 1\n",
    "        elif itemID in albumBiases:\n",
    "            sumAlbumRate += score\n",
    "            numAlbumRate += 1\n",
    "        elif itemID in artistBiases:\n",
    "            sumArtistRate += score\n",
    "            numArtistRate += 1\n",
    "        elif itemID in genreBiases:\n",
    "            sumGenreRate += score\n",
    "            numGenreRate += 1\n",
    "    if numTrackRate != 0:\n",
    "        userTaxBiases['track'] = sumTrackRate / float(numTrackRate) - aveRate\n",
    "    if numAlbumRate != 0:   \n",
    "        userTaxBiases['album'] = sumAlbumRate / float(numAlbumRate) - aveRate\n",
    "    if numArtistRate != 0:\n",
    "        userTaxBiases['artist'] = sumArtistRate / float(numArtistRate) - aveRate\n",
    "    if numGenreRate != 0:\n",
    "        userTaxBiases['genre'] = sumGenreRate / float(numGenreRate) - aveRate\n",
    "    \n",
    "    return userTaxBiases\n",
    "\n",
    "#pre-build the tax user biases\n",
    "userTaxBiases = {}\n",
    "for review in trainDatas:\n",
    "    userID = review['userID']\n",
    "    userTaxBiases[userID] = userTaxBias(userID)\n",
    "print('the number of users in train data is: ' + str(len(userTaxBiases)))\n",
    "# print(userTaxBiases['0'])\n",
    "\n",
    "def getUserSessionBias(ratings):\n",
    "    userSessionBias = {}\n",
    "    count = {}\n",
    "    for rating in ratings:\n",
    "        number = rating['number']\n",
    "        if number in userSessionBias:\n",
    "            userSessionBias[number] += float(rating['rating'])\n",
    "            count[number] += 1\n",
    "        else:\n",
    "            userSessionBias[number] = float(rating['rating'])\n",
    "            count[number] = 1\n",
    "    for number in userSessionBias.keys():\n",
    "        userSessionBias[number] = userSessionBias[number] / float(count[number]) - aveRate\n",
    "    return userSessionBias\n",
    "\n",
    "#get the user's session biases \n",
    "userSessionBiases = {}\n",
    "for review in trainDatas:\n",
    "    userID = review['userID']\n",
    "    userSessionBiases[userID] = getUserSessionBias(review['ratings'])\n",
    "    \n",
    "#check the RMSE with addtion of user session bias\n",
    "predRatings = []\n",
    "realRatings = []\n",
    "errors = []\n",
    "count = 0\n",
    "squareSum = 0\n",
    "for review in testDatas:\n",
    "    userID = review['userID']\n",
    "    if userID not in userBiases:\n",
    "        continue\n",
    "    for rating in review['ratings']:\n",
    "        itemID = rating['itemID']\n",
    "        realRating = float(rating['rating'])\n",
    "        count += 1\n",
    "        if itemID in itemBiases:\n",
    "            if itemID in trackBiases:\n",
    "                curItemBias = trackTaxBiases[itemID]\n",
    "                curUserBias = userTaxBiases[userID]['track']\n",
    "            elif itemID in albumBiases:\n",
    "                curItemBias = albumTaxBiases[itemID]\n",
    "                curUserBias = userTaxBiases[userID]['album']\n",
    "            else:\n",
    "                if itemID in artistBiases:\n",
    "                    curUserBias = userTaxBiases[userID]['artist']\n",
    "                elif itemID in genreBiases:\n",
    "                    curUserBias = userTaxBiases[userID]['genre']\n",
    "                curItemBias = itemBiases[itemID]\n",
    "        #if the current item does not exist in train data, the bias is zero\n",
    "        else:\n",
    "            curItemBias = 0\n",
    "        #check if user has session bias\n",
    "        if rating['number'] in userSessionBiases[userID]:\n",
    "            curUserBias += userSessionBiases[userID][rating['number']]\n",
    "        \n",
    "        \n",
    "        squareSum += (aveRate + curItemBias + curUserBias - realRating) ** 2 \n",
    "        predRatings.append(aveRate + curItemBias + curUserBias)\n",
    "        realRatings.append(realRating)\n",
    "        errors.append(aveRate + curItemBias + curUserBias - realRating)\n",
    "#         squareSum += (aveRate + userBiases[userID] + curItemBias + curUserBias - realRating) ** 2\n",
    "\n",
    "            \n",
    "RMSE = sqrt(squareSum / float(count))\n",
    "print('the full taxonomy model with user session bias RMSE is: ' + str(RMSE))\n",
    "print('the number of views in test data is: ' + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.6 Model with Learning Algorithm  **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Evaluation\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn the model on the training dataset using a stochastic gradient descent algorithm. And we then tested the results in terms of RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
